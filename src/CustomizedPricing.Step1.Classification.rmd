```{r set-options, echo=FALSE, cache=FALSE}
options(width=160)
opts_chunk$set(comment = "", warning = FALSE, message = FALSE, echo = TRUE, tidy = FALSE, size="small")
```


Customized Pricing v5 analysis
========================================================

Initilize R environment
-------------------------

Set language and load relevant packages.
```{r loadPackages, message=FALSE}
Sys.setenv(LANG = "en")

require("plyr")
require("ggplot2")
```


Preparing data for analysis
---------------------------

First set the working directory [NOTE: you need to modify the path below to the actual folder having the data file]. Then read the csv data files and have a quick look
```{r loadData}
#NEED TO FIRST SET R WORKING DIRECTORY TO WHERE THE FILES ARE LOCATED!!!
#setwd("~/PATH/TO/DATA/FILE")

dataT <- read.csv("../data/data.v5.masked.Training.csv", header=TRUE)
dataV <- read.csv("../data/data.v5.masked.Validation.csv", header=TRUE)
levels(dataV$Territory) = levels(dataT$Territory)

head(dataT, n=10)
```


Visualize the Training data set:
- distribution of *Discount* (taken out those cases with 0 discount)
```{r histogram}
hist(dataT[dataT$isDiscount,]$Discount, breaks=50)
```

- plot *Discount* as a function of *nContractQuantity*, colored by *Channel*
```{r visualization, fig.width=12}
qplot(x=nContractQuantity, y=Discount, colour=Channel, data=dataT)
```



Analysis Step 1. Classification
--------------------------------
To predict whom not to offer any discount. Here we will test multiple classification tools using the **Training** dataset: logistic regression, decision tree, random forest, and SVM, and choose the best.

# 1. logistic regression without using *Territory* variable.

- Setup and train the model
```{r logistic1.train}
logistic1.model <- glm(isDiscount ~ nContractQuantity + nInvoicePrice + Channel, data=dataT, family=binomial())

summary(logistic1.model)
```

- Validation using the **Validation** dataset: Predict *True* if the prob > 0.5, then count accuracy using the *table* function.
```{r logistic1.validation}
logistic1.valid <- dataV[c("Channel", "nContractQuantity", "nInvoicePrice", "Discount", "isDiscount")]
logistic1.valid$predP <- predict(logistic1.model, newdata=logistic1.valid, type="response")
logistic1.valid$pred1 <- logistic1.valid$predP>0.5

logistic1.table <- table(logistic1.valid$pred1, logistic1.valid$isDiscount)
logistic1.table
```


# 2. Logistic regression with *Territory* variable.
- Setup and train the model
```{r logistic2.train}
logistic2.model <- glm(isDiscount ~ nContractQuantity + nInvoicePrice + Channel + Territory, data=dataT, family=binomial())

summary(logistic2.model)
```

- Validation using the **Validation** dataset: Predict *True* if the prob > 0.5, then count accuracy using the *table* function.
```{r logistic2.validation}
logistic2.valid <- dataV[c("Channel", "Territory", "nContractQuantity", "nInvoicePrice", "Discount", "isDiscount")]
logistic2.valid$predP <- predict(logistic2.model, newdata=logistic2.valid, type="response")
logistic2.valid$pred1 <- logistic2.valid$predP>0.5

logistic2.table <- table(logistic2.valid$pred1, logistic2.valid$isDiscount)
logistic2.table
```

- Plot the ROC and accuracy curves.
```{r logistic2.plots}
require(ROCR)
logistic2.pred <- prediction(logistic2.valid$predP, logistic2.valid$isDiscount)
# Plot ROC curve
logistic2.ROC <- performance(logistic2.pred, measure = "tpr", x.measure = "fpr")
plot(logistic2.ROC)
# Plot precision/recall curve
#logistic2.precision <- performance(logistic2.pred, measure = "prec", x.measure = "rec")
#plot(logistic2.precision)
# Plot accuracy as function of threshold
logistic2.accuracy <- performance(logistic2.pred, measure = "acc")
plot(logistic2.accuracy)
```



# 3. Decision tree using the *rpart* package.
- Setup and train the model, then print summary.
```{r tree2.train}
require("rpart")
tree2.model <- rpart(as.factor(isDiscount) ~ nContractQuantity + nInvoicePrice + Channel + Territory, data=dataT)
summary(tree2.model)
printcp(tree2.model)
plotcp(tree2.model)
```


- plot the tree
```{r tree2.treeplot, fig.width=12}
plot(tree2.model, uniform=TRUE, main="Regression Tree for Mileage ")
text(tree2.model, use.n=TRUE, all=TRUE)
```

- validation
```{r tree2.validation}
tree2.valid <- dataV[c("Channel", "Territory", "nContractQuantity", "nInvoicePrice", "Discount", "isDiscount")]
tree2.valid$predP <- predict(tree2.model, newdata=tree2.valid, type="prob")[,"TRUE"]
tree2.valid$pred1 <- as.logical(predict(tree2.model, newdata=tree2.valid, type="class"))

tree2.table <- table(tree2.valid$pred1, tree2.valid$isDiscount)
tree2.table
```

- plot ROC.
```{r tree2.plot}
require(ROCR)
tree2.pred <- prediction(tree2.valid$predP, tree2.valid$isDiscount)
# Plot ROC curve
tree2.ROC <- performance(tree2.pred, measure = "tpr", x.measure = "fpr")
plot(tree2.ROC)
# Plot precision/recall curve
#tree2.precision <- performance(tree2.pred, measure = "prec", x.measure = "rec")
#plot(tree2.precision)
# Plot accuracy as function of threshold
tree2.accuracy <- performance(tree2.pred, measure = "acc")
plot(tree2.accuracy)
```





# 4. Random Forest prediction of isDiscount
- Train model and summary result. 
```{r forest1.train}
library(randomForest)
forest1.model <- randomForest(as.factor(isDiscount) ~ nContractQuantity  + nInvoicePrice + Channel, data=dataT)
summary(forest1.model)
print(forest1.model) # view results 
importance(forest1.model) #importance of each predictor
plot(forest1.model)
```

- Validation
```{r forest1.validation}
forest1.valid <- dataV[c("Channel", "nContractQuantity", "nInvoicePrice", "Discount", "isDiscount")]
forest1.valid$predP <- predict(forest1.model, newdata=forest1.valid, type="prob")[,"TRUE"]
forest1.valid$pred1 <- as.logical(predict(forest1.model, newdata=forest1.valid, type="response"))

forest1.table <- table(forest1.valid$pred1, forest1.valid$isDiscount)
forest1.table
```

- Plot ROC.
```{r forest1.plot}
require(ROCR)
forest1.pred <- prediction(forest1.valid$predP, forest1.valid$isDiscount)
# Plot ROC curve
forest1.ROC <- performance(forest1.pred, measure = "tpr", x.measure = "fpr")
plot(forest1.ROC)
# Plot precision/recall curve
#forest1.precision <- performance(forest1.pred, measure = "prec", x.measure = "rec")
#plot(forest1.precision)
# Plot accuracy as function of threshold
forest1.accuracy <- performance(forest1.pred, measure = "acc")
plot(forest1.accuracy)
```




# 5. SVM classification
- Train SVM
```{r svm.train}
require(e1071)

## first-time run of SVM requires optimization of parameters gamma and cost
#svm.tune <- tune.svm(as.factor(isDiscount) ~ nContractQuantity  + nInvoicePrice + Channel + Territory, data = dataT, validation.x=dataV, gamma = 2^(-1:5), cost = 10^(1:4), probability=TRUE)
#svm.model <- svm.tune$best.model

## directly use the obtained optimal parameter gamma=8, cost=10000
svm.model <- svm(as.factor(isDiscount) ~ nContractQuantity  + nInvoicePrice + Channel + Territory, data = dataT, cost = 10000, gamma = 8, probability=TRUE)
summary(svm.model)
```

- Validation
```{r svm.validation}
svm.valid <- dataV[c("Channel", "Territory", "nContractQuantity", "nInvoicePrice", "Discount", "isDiscount")]
svm.valid$pred1 <- as.logical(predict(svm.model, newdata=svm.valid))
svm.valid$predP <- attr(predict(svm.model, newdata=svm.valid, probability=TRUE), "probabilities")[,"TRUE"]

svm.table <- table(svm.valid$pred1, svm.valid$isDiscount)
svm.table
```

- Plot ROC
```{r svm.plot}
require(ROCR)
svm.pred <- prediction(svm.valid$predP, svm.valid$isDiscount)
# Plot ROC curve
svm.ROC <- performance(svm.pred, measure = "tpr", x.measure = "fpr")
plot(svm.ROC)
# Plot precision/recall curve
#svm.precision <- performance(svm.pred, measure = "prec", x.measure = "rec")
#plot(svm.precision)
# Plot accuracy as function of threshold
svm.accuracy <- performance(svm.pred, measure = "acc")
plot(svm.accuracy)
```

- Visualize the SVM model
```{r svm.visualization}
#plot(svm.model, data = dataV, formula = nContractQuantity ~ nInvoicePrice)
```


